{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilede_utils import request_car_detail_page\n",
    "\n",
    "html = request_car_detail_page('358672814')\n",
    "\n",
    "with open('car.html', 'w') as f:\n",
    "    f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "request_mobile_de_page() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/pate/studies/intro-datascience/importEVorNot/mobile_de/mobilede_notebook.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pate/studies/intro-datascience/importEVorNot/mobile_de/mobilede_notebook.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcar_mapping\u001b[39;00m \u001b[39mimport\u001b[39;00m CAR_MAKE_MAP, CAR_MAKE_MODEL_MAP\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pate/studies/intro-datascience/importEVorNot/mobile_de/mobilede_notebook.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmobilede_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m request_mobile_de_page\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pate/studies/intro-datascience/importEVorNot/mobile_de/mobilede_notebook.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m search_page \u001b[39m=\u001b[39m request_mobile_de_page(\u001b[39m'\u001b[39;49m\u001b[39mvolkswage\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mid.3\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pate/studies/intro-datascience/importEVorNot/mobile_de/mobilede_notebook.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39msearch.html\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pate/studies/intro-datascience/importEVorNot/mobile_de/mobilede_notebook.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     f\u001b[39m.\u001b[39mwrite(search_page)\n",
      "\u001b[0;31mTypeError\u001b[0m: request_mobile_de_page() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from car_mapping import CAR_MAKE_MAP, CAR_MAKE_MODEL_MAP\n",
    "from mobilede_utils import request_search_page\n",
    "\n",
    "search_page = request_search_page('volkswage', 'id.3')\n",
    "\n",
    "with open('search.html', 'w') as f:\n",
    "    f.write(search_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilede_utils import request_mobile_de_page\n",
    "\n",
    "url = '/fahrzeuge/details.html?id=372947832&cn=DE&fuels=ELECTRICITY&isSearchRequest=true&pageNumber=1&scopeId=C&sortOption.sortBy=creationTime&sortOption.sortOrder=DESCENDING&action=topOfPage&top=1:1&searchId=6421ed5b-1df1-1ccc-bd0c-b44042c43503&ref=srp'\n",
    "html = request_mobile_de_page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'extract_car_data2' from 'mobilede_parser' (/home/toniramo/Documents/intro_to_DS_2023p1/project/importEVorNot/mobile_de/mobilede_parser.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21855/3436995928.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmobilede_parser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_car_data2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mextract_car_data2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'extract_car_data2' from 'mobilede_parser' (/home/toniramo/Documents/intro_to_DS_2023p1/project/importEVorNot/mobile_de/mobilede_parser.py)"
     ]
    }
   ],
   "source": [
    "from mobilede_parser import extract_car_data\n",
    "\n",
    "extract_car_data(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from mobilede_utils import request_mobile_de_page\n",
      "from mobilede_parser import extract_car_data\n",
      "\n",
      "url = 'https://suchen.mobile.de/fahrzeuge/details.html?id=372947832&cn=DE&fuels=ELECTRICITY&isSearchRequest=true&pageNumber=1&scopeId=C&sortOption.sortBy=creationTime&sortOption.sortOrder=DESCENDING&action=topOfPage&top=1:1&searchId=6421ed5b-1df1-1ccc-bd0c-b44042c43503&ref=srp'\n",
      "html = request_mobile_de_page(url)\n",
      "from mobilede_utils import request_mobile_de_page\n",
      "from mobilede_parser import extract_car_data\n",
      "\n",
      "url = 'fahrzeuge/details.html?id=372947832&cn=DE&fuels=ELECTRICITY&isSearchRequest=true&pageNumber=1&scopeId=C&sortOption.sortBy=creationTime&sortOption.sortOrder=DESCENDING&action=topOfPage&top=1:1&searchId=6421ed5b-1df1-1ccc-bd0c-b44042c43503&ref=srp'\n",
      "html = request_mobile_de_page(url)\n",
      "from mobilede_utils import request_mobile_de_page\n",
      "from mobilede_parser import extract_car_data\n",
      "\n",
      "url = '/fahrzeuge/details.html?id=372947832&cn=DE&fuels=ELECTRICITY&isSearchRequest=true&pageNumber=1&scopeId=C&sortOption.sortBy=creationTime&sortOption.sortOrder=DESCENDING&action=topOfPage&top=1:1&searchId=6421ed5b-1df1-1ccc-bd0c-b44042c43503&ref=srp'\n",
      "html = request_mobile_de_page(url)\n",
      "extract_car_data(html)\n",
      "extract_car_data(html)\n",
      "from mobilede_parser import extract_car_data\n",
      "\n",
      "extract_car_data(html)\n",
      "from mobilede_parser import extract_car_data\n",
      "\n",
      "extract_car_data(html)\n",
      "from mobilede_parser import extract_car_data\n",
      "\n",
      "extract_car_data(html)\n",
      "from mobilede_parser import extract_car_data\n",
      "\n",
      "extract_car_data(html)\n",
      "from mobilede_parser import extract_car_data\n",
      "\n",
      "extract_car_data(html)\n",
      "from mobilede_parser import extract_car_data\n",
      "\n",
      "extract_car_data(html)\n",
      "from mobilede_parser import extract_car_data\n",
      "\n",
      "extract_car_data(html)\n",
      "from mobilede_parser import extract_car_dataa\n",
      "\n",
      "extract_car_data(html)\n",
      "from mobilede_parser import extract_car_data\n",
      "\n",
      "extract_car_data(html)\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    print(\"test\")\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"features\"] = data[\"features\"].append({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "import unicodedata\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    print(\"test\")\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"features\"] = data[\"features\"].append({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    print(\"test\")\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"features\"] = data[\"features\"].append({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    print(\"test\")\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"features\"] = data[\"features\"].append({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    print(\"test\")\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    data[\"features\"] = data[\"features\"].append({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else None)})\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    print(\"test\")\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    data[\"test\"] = {\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else None)}\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    print(\"test\")\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    data[\"test\"] = {\"Parking sensors\" : (s.get_text().split(\",\") if (s:= soup.find(id=\"parkAssists-v\")) else None)}\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    print(\"test\")\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    data[\"test\"] = {\"parking_sensors\" : (s.get_text().split(\",\") if (s:= soup.find(id=\"parkAssists-v\")) else None)}\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    print(\"test\")\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    data[\"test\"] = data[\"features\"].append({\"parking_sensors\" : (s.get_text().split(\",\") if (s:= soup.find(id=\"parkAssists-v\")) else None)})\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    print(\"test\")\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    data[\"features\"].append({\"parking_sensors\" : (s.get_text().split(\",\") if (s:= soup.find(id=\"parkAssists-v\")) else None)})\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    print(\"test\")\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    data[\"features\"].append({\"parking_sensors\" : (s.get_text().split(\",\") if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    print(\"test\")\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    data[\"features\"].append(map(lambda x: f\"Parking sensor: {x}\", (s.get_text().split(\",\") if (s:= soup.find(id=\"parkAssists-v2\")) else None)))\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    print(\"test\")\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    data[\"features\"].append(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v2\")) else None\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    data[\"features\"].append(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v2\")) else None\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    data[\"features\"].append(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    data[\"features\"].append(list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\")))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    data[\"features\"].join(list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\")))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    data[\"features\"].append(*list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\")))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    data[\"features\"].append(**list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\")))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    data[\"features\"].append(*(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\")))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    (data[\"features\"].append(*(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    (data[\"features\"].append(**(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    data[\"features\"].append(list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\")))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    data[\"features\"] = data[\"features\"].join(list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\")))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    (data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\")))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"features\"] = data[\"features\"] + (map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\")))\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\")))\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"mileage_km\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price_e\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\" \n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"color\"] = s.get_text() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    data[\"number_of_previous_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"number_of_previous_owners\"] = s.get_text()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = soup.find(id=\"transmission-v\") == \"Automatik\"\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"color\"] = s.get_text() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    data[\"number_of_previous_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"number_of_previous_owners\"] = s.get_text()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if(s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"color\"], color[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if(s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"color\"], [\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if(s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if(s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    data[\"t1\"], data[\"t2\"] = \"Testi\".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if(s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    data[\"t1\"], data[\"t2\"] = \"Testi \".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if(s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def _text_or_none(element):\n",
      "    return element.get_text() if element else None\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    data[\"t1\"], data[\"t2\"] = \"Testi \".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
      "    #data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"undamaged\"] = _text_or_none(soup.find(id=\"damageCondition-v\")) == \"Unfallfrei\"\n",
      "\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def _text_or_none(element):\n",
      "    return element.get_text() if element else None\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    #data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    data[\"t1\"], data[\"t2\"] = \"Testi \".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
      "    #data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"undamaged\"] = _text_or_none(soup.find(id=\"damageCondition-v\")) == \"Unfallfrei\"\n",
      "\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def _text_or_none(element):\n",
      "    return element.get_text() if element else None\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    #data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    #data[\"t1\"], data[\"t2\"] = \"Testi \".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
      "    #data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"undamaged\"] = _text_or_none(soup.find(id=\"damageCondition-v\")) == \"Unfallfrei\"\n",
      "\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def _text_or_none(element):\n",
      "    return element.get_text() if element else None\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    #data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    #data[\"t1\"], data[\"t2\"] = \"Testi \".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
      "    #data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    data[\"undamaged\"] = _text_or_none(soup.find(id=\"damageCondition-v2\")) == \"Unfallfrei\"\n",
      "\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "\"Test\".split()\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def _text_or_none(element):\n",
      "    return element.get_text() if element else None\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    color = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    data[\"color\"], data[\"color_type\"] = color if len(color) > 1 else color[0], None\n",
      "    #data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    #data[\"t1\"], data[\"t2\"] = \"Testi \".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    #data[\"undamaged\"] = s == \"Unfallfrei\" if (s:= _text_or_none(soup.find(id=\"damageCondition-v2\"))) else None\n",
      "\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def _text_or_none(element):\n",
      "    return element.get_text() if element else None\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    color =  s.get_text().split() if (s:=soup.find(id=\"color-v2\")) else None\n",
      "    data[\"color\"], data[\"color_type\"] = color if len(color) > 1 else color[0], None\n",
      "    #data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    #data[\"t1\"], data[\"t2\"] = \"Testi \".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    #data[\"undamaged\"] = s == \"Unfallfrei\" if (s:= _text_or_none(soup.find(id=\"damageCondition-v2\"))) else None\n",
      "\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def _text_or_none(element):\n",
      "    return element.get_text() if element else None\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    color =  s.get_text().split() if (s:=soup.find(id=\"color-v2\")) else None\n",
      "    data[\"color\"], data[\"color_type\"] = color if color and len(color) > 1 else color[0], None\n",
      "    #data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    #data[\"t1\"], data[\"t2\"] = \"Testi \".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    #data[\"undamaged\"] = s == \"Unfallfrei\" if (s:= _text_or_none(soup.find(id=\"damageCondition-v2\"))) else None\n",
      "\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def _text_or_none(element):\n",
      "    return element.get_text() if element else None\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    color =  s.get_text().split() if (s:=soup.find(id=\"color-v2\")) else []\n",
      "    data[\"color\"], data[\"color_type\"] = color if len(color) > 1 else color[0], None\n",
      "    #data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    #data[\"t1\"], data[\"t2\"] = \"Testi \".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    #data[\"undamaged\"] = s == \"Unfallfrei\" if (s:= _text_or_none(soup.find(id=\"damageCondition-v2\"))) else None\n",
      "\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def _text_or_none(element):\n",
      "    return element.get_text() if element else None\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    color =  s.get_text().split() if (s:=soup.find(id=\"color-v2\")) else [None]\n",
      "    data[\"color\"], data[\"color_type\"] = color if len(color) > 1 else color[0], None\n",
      "    #data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    #data[\"t1\"], data[\"t2\"] = \"Testi \".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    #data[\"undamaged\"] = s == \"Unfallfrei\" if (s:= _text_or_none(soup.find(id=\"damageCondition-v2\"))) else None\n",
      "\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def _text_or_none(element):\n",
      "    return element.get_text() if element else None\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"color\"], data[\"color_type\"] =  s.get_text().split().append(None) if (s:=soup.find(id=\"color-v2\")) else [None, None]\n",
      "    #data[\"color\"], data[\"color_type\"] = color if len(color) > 1 else color[0], None\n",
      "    #data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    #data[\"t1\"], data[\"t2\"] = \"Testi \".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    #data[\"undamaged\"] = s == \"Unfallfrei\" if (s:= _text_or_none(soup.find(id=\"damageCondition-v2\"))) else None\n",
      "\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def _text_or_none(element):\n",
      "    return element.get_text() if element else None\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"color\"], data[\"color_type\"] =  s.get_text().split().append(None) if (s:=soup.find(id=\"color-v\")) else [None, None]\n",
      "    #data[\"color\"], data[\"color_type\"] = color if len(color) > 1 else color[0], None\n",
      "    #data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    #data[\"t1\"], data[\"t2\"] = \"Testi \".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    #data[\"undamaged\"] = s == \"Unfallfrei\" if (s:= _text_or_none(soup.find(id=\"damageCondition-v2\"))) else None\n",
      "\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def _text_or_none(element):\n",
      "    return element.get_text() if element else None\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"color\"], data[\"color_type\"], =  s.get_text().split().append(None) if (s:=soup.find(id=\"color-v\")) else [None, None]\n",
      "    #data[\"color\"], data[\"color_type\"] = color if len(color) > 1 else color[0], None\n",
      "    #data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    #data[\"t1\"], data[\"t2\"] = \"Testi \".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    #data[\"undamaged\"] = s == \"Unfallfrei\" if (s:= _text_or_none(soup.find(id=\"damageCondition-v2\"))) else None\n",
      "\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def _text_or_none(element):\n",
      "    return element.get_text() if element else None\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"color\"], data[\"color_type\"],_ =  s.get_text().split().append(None) if (s:=soup.find(id=\"color-v\")) else [None, None]\n",
      "    #data[\"color\"], data[\"color_type\"] = color if len(color) > 1 else color[0], None\n",
      "    #data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    #data[\"t1\"], data[\"t2\"] = \"Testi \".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    #data[\"undamaged\"] = s == \"Unfallfrei\" if (s:= _text_or_none(soup.find(id=\"damageCondition-v2\"))) else None\n",
      "\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "\"Test \".split().append(None)\n",
      "\"Test \".split().append(None)\n",
      "print(\"Test \".split().append(None))\n",
      "print(\"Test te\".split().append(None))\n",
      "print(\"Test te\".split())\n",
      "print(\"Test te\".split().append([]))\n",
      "print(\"Test te\".split().append([None]))\n",
      "print(\"Test te\".split().append(\"\"))\n",
      "print(\"Test te\".split().append(\"t\"))\n",
      "print(\"Test te\".split().append(\"t\"))\n",
      "print(\"Test te\".split())\n",
      "print(\"Test te\".split() + [None])\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def _text_or_none(element):\n",
      "    return element.get_text() if element else None\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"color\"], data[\"color_type\"],_ =  s.get_text().split() + [None] if (s:=soup.find(id=\"color-v\")) else [None, None]\n",
      "    #data[\"color\"], data[\"color_type\"] = color if len(color) > 1 else color[0], None\n",
      "    #data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    #data[\"t1\"], data[\"t2\"] = \"Testi \".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    #data[\"undamaged\"] = s == \"Unfallfrei\" if (s:= _text_or_none(soup.find(id=\"damageCondition-v2\"))) else None\n",
      "\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "from bs4 import BeautifulSoup\n",
      "import unicodedata\n",
      "import re\n",
      "\n",
      "def _parse_number(string):\n",
      "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
      "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
      "\n",
      "def _text_or_none(element):\n",
      "    return element.get_text() if element else None\n",
      "\n",
      "def extract_car_data2(html):\n",
      "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
      "    soup = BeautifulSoup(page_n, 'html.parser')\n",
      "\n",
      "    data = {}\n",
      "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
      "    data[\"color\"], data[\"color_type\"] =  s.get_text().split() + [None] if (s:=soup.find(id=\"color-v\")) else [None, None]\n",
      "    #data[\"color\"], data[\"color_type\"] = color if len(color) > 1 else color[0], None\n",
      "    #data[\"color\"], data[\"color_type\"] = s.get_text().split() if (s:=soup.find(id=\"color-v\")) else None\n",
      "    #data[\"t1\"], data[\"t2\"] = \"Testi \".split()\n",
      "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
      "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
      "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
      "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
      "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
      "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
      "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
      "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
      "    #data[\"undamaged\"] = s == \"Unfallfrei\" if (s:= _text_or_none(soup.find(id=\"damageCondition-v2\"))) else None\n",
      "\n",
      "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")) else None\n",
      "    \n",
      "    data[\"accessories\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
      "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
      "        data[\"accessories\"] = data[\"accessories\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
      "\n",
      "    data[\"n_prev_owners\"] = None\n",
      "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
      "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
      "        data[\"n_prev_owners\"] = s.get_text()\n",
      "    \n",
      "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
      "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
      "    #data[\"test\"] = \n",
      "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
      "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
      "\n",
      "    return data\n",
      "\n",
      "extract_car_data2(html)\n",
      "%history\n"
     ]
    }
   ],
   "source": [
    "%history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brand': 'Opel',\n",
       " 'model': 'Astra',\n",
       " 'color': 'Blau',\n",
       " 'color_type': 'Metallic',\n",
       " 'kilometers': '2500',\n",
       " 'price': '47980',\n",
       " 'registration': '06/2023',\n",
       " 'electric': True,\n",
       " 'power_kw': '115',\n",
       " 'capacity_kwh': None,\n",
       " 'automatic': True,\n",
       " 'undamaged': True,\n",
       " 'el_cons_kwh100km': '14.8',\n",
       " 'n_prev_owners': '1',\n",
       " 'features': ['ABS',\n",
       "  'Abstandstempomat',\n",
       "  'Abstandswarner',\n",
       "  'Ambiente-Beleuchtung',\n",
       "  'Android Auto',\n",
       "  'Apple CarPlay',\n",
       "  'Armlehne',\n",
       "  'Beheizbare Frontscheibe',\n",
       "  'Beheizbares Lenkrad',\n",
       "  'Berganfahrassistent',\n",
       "  'Blendfreies Fernlicht',\n",
       "  'Bluetooth',\n",
       "  'Bordcomputer',\n",
       "  'Elektr. Fensterheber',\n",
       "  'Elektr. Seitenspiegel',\n",
       "  'Elektr. Wegfahrsperre',\n",
       "  'ESP',\n",
       "  'Freisprecheinrichtung',\n",
       "  'Garantie',\n",
       "  'Head-Up Display',\n",
       "  'Induktionsladen für Smartphones',\n",
       "  'Innenspiegel autom. abblendend',\n",
       "  'Isofix',\n",
       "  'Lederlenkrad',\n",
       "  'LED-Scheinwerfer',\n",
       "  'LED-Tagfahrlicht',\n",
       "  'Leichtmetallfelgen',\n",
       "  'Lichtsensor',\n",
       "  'Lordosenstütze',\n",
       "  'Müdigkeitswarner',\n",
       "  'Multifunktionslenkrad',\n",
       "  'Navigationssystem',\n",
       "  'Nebelscheinwerfer',\n",
       "  'Nichtraucher-Fahrzeug',\n",
       "  'Notbremsassistent',\n",
       "  'Notrufsystem',\n",
       "  'Pannenkit',\n",
       "  'Radio DAB',\n",
       "  'Regensensor',\n",
       "  'Reifendruckkontrolle',\n",
       "  'Scheckheftgepflegt',\n",
       "  'Schiebedach',\n",
       "  'Servolenkung',\n",
       "  'Sitzheizung',\n",
       "  'Sommerreifen',\n",
       "  'Sportpaket',\n",
       "  'Sportsitze',\n",
       "  'Sprachsteuerung',\n",
       "  'Spurhalteassistent',\n",
       "  'Totwinkel-Assistent',\n",
       "  'Touchscreen',\n",
       "  'Traktionskontrolle',\n",
       "  'Tuner/Radio',\n",
       "  'Verkehrszeichenerkennung',\n",
       "  'Zentralverriegelung',\n",
       "  'Parking sensor: Vorne',\n",
       "  'Parking sensor: Hinten',\n",
       "  'Parking sensor: 360°-Kamera']}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def _parse_number(string):\n",
    "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
    "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
    "\n",
    "def _text_or_none(element):\n",
    "    return element.get_text() if element else None\n",
    "\n",
    "def extract_car_data2(html):\n",
    "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
    "    soup = BeautifulSoup(page_n, 'html.parser')\n",
    "\n",
    "    data = {}\n",
    "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
    "    data[\"color\"], data[\"color_type\"], *_ =  s.get_text().split() + [\"Nonmetallic\"] if (s:=soup.find(id=\"color-v\")) else [None, None]\n",
    "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
    "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
    "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
    "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
    "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
    "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
    "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
    "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if  (s := soup.find(id=\"damageCondition-v\")) else None\n",
    "\n",
    "    data[\"el_cons_kwh100km\"] = None\n",
    "    if (s:= soup.find(id=\"envkv.wltp.powerConsumption-v\")):\n",
    "        data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0])\n",
    "    \n",
    "    data[\"n_prev_owners\"] = None\n",
    "    if (s:= (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
    "                 .find(\"div\", {\"class\" : \"key-feature__value\"}))):\n",
    "        data[\"n_prev_owners\"] = s.get_text()\n",
    "    \n",
    "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
    "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
    "        data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
    "\n",
    "    #data[\"test\"] = (soup.find(id=\"parkAssists-v\"))\n",
    "    #print({\"Parking sensors\" : (s.get_text() if (s:= soup.find(id=\"parkAssists-v\")) else 0)})\n",
    "    #data[\"test\"] = \n",
    "    #data[\"features\"].append({\"Parking sensor\" : (map(s.get_text().split(\",\")) if (s:= soup.find(id=\"parkAssists-v2\")) else None)})\n",
    "    #data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x}\", s.get_text().split(\",\"))) if (s:= soup.find(id=\"parkAssists-v\")) else None\n",
    "\n",
    "    return data\n",
    "\n",
    "extract_car_data2(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brand': 'Opel',\n",
       " 'model': 'Astra',\n",
       " 'color': 'Blau',\n",
       " 'color_type': 'Metallic',\n",
       " 'kilometers': '2500',\n",
       " 'price': '47980',\n",
       " 'registration': '06/2023',\n",
       " 'electric': True,\n",
       " 'power_kw': '115',\n",
       " 'capacity_kwh': None,\n",
       " 'automatic': True,\n",
       " 'undamaged': True,\n",
       " 'el_cons_kwh100km': '14.8',\n",
       " 'n_prev_owners': '1',\n",
       " 'features': ['ABS',\n",
       "  'Abstandstempomat',\n",
       "  'Abstandswarner',\n",
       "  'Ambiente-Beleuchtung',\n",
       "  'Android Auto',\n",
       "  'Apple CarPlay',\n",
       "  'Armlehne',\n",
       "  'Beheizbare Frontscheibe',\n",
       "  'Beheizbares Lenkrad',\n",
       "  'Berganfahrassistent',\n",
       "  'Blendfreies Fernlicht',\n",
       "  'Bluetooth',\n",
       "  'Bordcomputer',\n",
       "  'Elektr. Fensterheber',\n",
       "  'Elektr. Seitenspiegel',\n",
       "  'Elektr. Wegfahrsperre',\n",
       "  'ESP',\n",
       "  'Freisprecheinrichtung',\n",
       "  'Garantie',\n",
       "  'Head-Up Display',\n",
       "  'Induktionsladen für Smartphones',\n",
       "  'Innenspiegel autom. abblendend',\n",
       "  'Isofix',\n",
       "  'Lederlenkrad',\n",
       "  'LED-Scheinwerfer',\n",
       "  'LED-Tagfahrlicht',\n",
       "  'Leichtmetallfelgen',\n",
       "  'Lichtsensor',\n",
       "  'Lordosenstütze',\n",
       "  'Müdigkeitswarner',\n",
       "  'Multifunktionslenkrad',\n",
       "  'Navigationssystem',\n",
       "  'Nebelscheinwerfer',\n",
       "  'Nichtraucher-Fahrzeug',\n",
       "  'Notbremsassistent',\n",
       "  'Notrufsystem',\n",
       "  'Pannenkit',\n",
       "  'Radio DAB',\n",
       "  'Regensensor',\n",
       "  'Reifendruckkontrolle',\n",
       "  'Scheckheftgepflegt',\n",
       "  'Schiebedach',\n",
       "  'Servolenkung',\n",
       "  'Sitzheizung',\n",
       "  'Sommerreifen',\n",
       "  'Sportpaket',\n",
       "  'Sportsitze',\n",
       "  'Sprachsteuerung',\n",
       "  'Spurhalteassistent',\n",
       "  'Totwinkel-Assistent',\n",
       "  'Touchscreen',\n",
       "  'Traktionskontrolle',\n",
       "  'Tuner/Radio',\n",
       "  'Verkehrszeichenerkennung',\n",
       "  'Zentralverriegelung',\n",
       "  'Parking sensor: Vorne',\n",
       "  'Parking sensor: Hinten',\n",
       "  'Parking sensor: 360°-Kamera']}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse(html):\n",
    "    page_n = unicodedata.normalize(\"NFKD\", html)\n",
    "    soup = BeautifulSoup(page_n, 'html.parser')\n",
    "\n",
    "    data = {}\n",
    "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
    "    data[\"color\"], data[\"color_type\"], *_ =  s.get_text().split() + [\"Nonmetallic\"] if (s:=soup.find(id=\"color-v\")) else [None, None]\n",
    "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
    "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
    "    data[\"registration\"] = soup.find(id=\"firstRegistration-v\").get_text()\n",
    "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
    "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
    "    data[\"capacity_kwh\"] = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else None\n",
    "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
    "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if (s := soup.find(id=\"damageCondition-v\")) else None\n",
    "    s = soup.find(id=\"envkv.wltp.powerConsumption-v\")\n",
    "    data[\"el_cons_kwh100km\"] = (\".\").join(re.findall(r\"(\\d+),(\\d+)\", s.get_text())[0]) if s else None\n",
    "    s = (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
    "             .find(\"div\", {\"class\" : \"key-feature__value\"}))\n",
    "    data[\"n_prev_owners\"] = s.get_text() if s else None\n",
    "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
    "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
    "        data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
    "        \n",
    "    return data\n",
    "\n",
    "parse(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_n = unicodedata.normalize(\"NFKD\", html)\n",
    "soup = BeautifulSoup(page_n, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['40 kWh', '50kwh']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_capacity(soup):\n",
    "    res = _parse_number(s.get_text()) if (s:= soup.find(id=\"batteryCapacity-v\")) else []\n",
    "\n",
    "    if (res == []):\n",
    "        s = soup.find(\"div\", {\"class\": \"listing-title\"}).find(\"div\", {\"class\": \"listing-subtitle\"})\n",
    "        res = re.findall(\"(\\d{2,3})\\s*kWh\", s.get_text(), re.I) if s else []\n",
    "\n",
    "    if (res == []):\n",
    "        s = soup.find(\"div\", {\"class\", \"g-col-12 description\"})\n",
    "        res = re.findall(\"(\\d{2,3})\\s*kWh\", s.get_text(), re.I) if s else []\n",
    "\n",
    "    if len(res):\n",
    "        return sorted(res, reverse=True)[0]\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "#if (s1 == []):\n",
    "#    s1 = re.findall(\"\\d{2,3}\\s*kWh\", s.get_text(), re.I)\n",
    "\n",
    "#sorted(s1, reverse=True)[0]\n",
    "#s1 = re.findall(\"\\d{2,3}\\s*kWh\", s, re.I)\n",
    "#if s1 == []:\n",
    "\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if s not:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_capacity(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50kwh'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = soup.find(\"div\", {\"class\", \"g-col-12 description\"}).get_text() + \" 40 kWh , 50kwh \"\n",
    "s1 = re.findall(\"\\d{2,3}\\s*kWh\", s, re.I)\n",
    "sorted(s1, reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_number(string):\n",
    "    \"\"\"Parse e.g. 43.400 € to 43400 or 12.500 km to 12500\"\"\"\n",
    "    return (\"\").join(re.findall(r\"\\d+\", string))\n",
    "\n",
    "def _parse_capacity(s):\n",
    "    return re.findall(\"(\\d{2,3})\\s*kWh\", s.get_text(), re.I) if s else []\n",
    "\n",
    "def _get_capacity(soup):\n",
    "    res = _parse_capacity(soup.find(id=\"batteryCapacity-v\"))\n",
    "\n",
    "    if res == []:\n",
    "        res = _parse_capacity(soup.find(\"div\", {\"class\": \"listing-title\"}).find(\"div\", {\"class\": \"listing-subtitle\"}))\n",
    "    if res == []:\n",
    "        res = _parse_capacity(soup.find(\"div\", {\"class\", \"g-col-12 description\"}))\n",
    "    if len(res):\n",
    "        return sorted(res, reverse=True)[0]\n",
    "\n",
    "    return None\n",
    "\n",
    "def extract_car_data(file):\n",
    "    with open(file) as f:\n",
    "        #html = unicodedata.normalize(\"NFKD\", f)\n",
    "        soup = BeautifulSoup(f, 'html.parser')\n",
    "    #page_n = unicodedata.normalize(\"NFKD\", html)\n",
    "    \n",
    "\n",
    "    data = {}\n",
    "    data[\"brand\"], data[\"model\"] = soup.find(id=\"ad-title\").get_text().split(\" \", 1)\n",
    "    data[\"color\"], data[\"color_type\"], *_ =  s.get_text().split() + [\"Nonmetallic\"] if (s:=soup.find(id=\"color-v\")) else [None, None]\n",
    "    data[\"kilometers\"] = _parse_number(soup.find(id=\"mileage-v\").get_text())\n",
    "    data[\"price\"] = _parse_number(soup.find(\"span\", {\"data-testid\" : \"prime-price\"}).get_text())\n",
    "    data[\"registration\"] = s.get_text() if (s:=soup.find(id=\"firstRegistration-v\")) else None\n",
    "    data[\"electric\"] = soup.find(id=\"fuel-v\").get_text() == \"Elektro\"\n",
    "    data[\"power_kw\"] = re.findall(r\"\\d+\", soup.find(id=\"power-v\").get_text())[0]\n",
    "    data[\"capacity_kwh\"] = _get_capacity(soup)\n",
    "    data[\"automatic\"] = s.get_text() == \"Automatik\" if (s:=soup.find(id=\"transmission-v\")) else None\n",
    "    data[\"undamaged\"] = s.get_text() == \"Unfallfrei\" if (s := soup.find(id=\"damageCondition-v\")) else None\n",
    "    s= soup.find(id=\"envkv.wltp.powerConsumption-v\")\n",
    "    data[\"el_cons_kwh100km\"] = re.search(r\"(\\d+,\\d+)\", s.get_text()) if s else None\n",
    "    #data[\"el_cons_kwh100km\"] = (\".\").join(re.search(r\"(\\d+),(\\d+)\", s.get_text())) if s else None\n",
    "    s = (soup.find(\"div\", {\"class\" : \"key-feature key-feature--numberOfPreviousOwners\"})\n",
    "             .find(\"div\", {\"class\" : \"key-feature__value\"}))\n",
    "    data[\"n_prev_owners\"] = s.get_text() if s else None\n",
    "    data[\"n_seats\"] = s.get_text() if (s:= soup.find(id=\"numSeats-v\")) else None\n",
    "    data[\"features\"] = [item.get_text() for item in soup.find(id=\"features\").find_all(\"div\", {\"class\" : \"bullet-list\"})]\n",
    "    if (s:= soup.find(id=\"parkAssists-v\")):\n",
    "        data[\"features\"] = data[\"features\"] + list(map(lambda x: f\"Parking sensor: {x.strip()}\", s.get_text().split(\",\")))\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21855/1300374496.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract_car_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"car3.html\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_21855/2631156349.py\u001b[0m in \u001b[0;36mextract_car_data\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kilometers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mileage-v\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"price\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"span\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"data-testid\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"prime-price\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"registration\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"firstRegistration-v\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"electric\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fuel-v\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Elektro\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"power_kw\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\d+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"power-v\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "extract_car_data(\"car3.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".replace(\"c\", \"a\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
